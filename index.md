---
layout: homepage
---

<h1 id="about-me"></h1>

<h2 style="margin: 80px 0px 10px;"></h2>

I am an Associate Professor at [Xi'an Jiaotong University](http://en.xjtu.edu.cn/XJTU_Introduction/Introduction.htm) (XJTU), China. I was a postdocÂ at [CISPA Helmholtz Center for Information Security](https://cispa.de/en/about), Germany, hosted by [Prof. Michael Backes](https://michaelbackes.eu/aboutme.html).
I received my PhD from [Radboud University](https://www.ru.nl/english/), Netherlands, supervised by [Prof. Martha Larson](https://www.ru.nl/english/people/larson-m/). My general research interest is <strong>Adversarial Machine Learning</strong>; Most of my work has concentrated on analyzing the vulnerability of deep neural networks (e.g., computer vision and large vision-language models) to various attacks (e.g., adversarial examples and data poisons). I sometimes contribute to projects on media forensics, including AI-generated media detection.

## Resources 
- **[A curated list for large model safety, security, and privacy papers, leaderboards...](https://github.com/ThuCCSLab/lm-ssp)** <img alt="Stars" src="https://img.shields.io/github/stars/ThuCCSLab/lm-ssp">
- **[A curated list for AI security & privacy workshops, tutorials, seminars...](https://github.com/ZhengyuZhao/AI-Security-and-Privacy-Events)** <img alt="Stars" src="https://img.shields.io/github/stars/ZhengyuZhao/AI-Security-and-Privacy-Events">
- **[A curated list for transferable adversarial example papers](https://github.com/ZhengyuZhao/TransferAttackEval)** <img alt="Stars" src="https://img.shields.io/github/stars/ZhengyuZhao/TransferAttackEval">

## Services
<ul style="margin:-5px 0 25px;width:950px">
  <li><strong>Poster Session Co-Chair</strong> of ACM MM 2019</li>
  <li><strong>Area Chair</strong> of NeurIPS, <strong>Senior Program Committee</strong> of AAAI</li>
  <li><strong>Program Committee</strong> of ICLR, ICML, CVPR, ICCV, ECCV, ACL, IJCAI, AISTATS, BMVC, FAccT</li>
  <li><strong>Journal Reviewer</strong> of TPAMI, TIFS, TKDE, TDSC, TCSS, IJCV, PR</li>
  <li><strong>Task Co-Organizer</strong> of <a href="https://multimediaeval.github.io/editions/2020/tasks/pixelprivacy/">Pixel Privacy</a> and <a href="http://www.multimediaeval.org/mediaeval2019/multimediasatellite/">Multimedia Satellite</a> at <a href="https://multimediaeval.github.io/">MediaEval</a> 2018-2020</li>
</ul>

## Honors & Awards 
<ul style="margin:-5px 0 25px;width:950px">
<li>Doctoral Consortium Award, CVPR 2021</li>
<li>Outstanding Reviewer of NeurIPS 2023 (~10%), AISTATS 2023 (~11%), BMVC 2022 (~8%), BMVC 2020 (~6%)</li>
<li>2nd place in <a href="https://icml-tifa.github.io/challenges/track1/">ICML 2024 Competition on Black-box Adversarial Attacks against Multimodal Large Language Models</a></li>
<li>3rd place in <a href="https://cvpr24-advml.github.io/">CVPR 2024 Competition on Black-box Adversarial Attacks against Vision-Language Models</a></li>
<li>Top 1% in <a href="https://aisecure-workshop.github.io/amlcvpr2021/">CVPR 2021 Competition on Black-box Adversarial Attacks against ImageNet Classifiers</a></li>
<li>Student Travel Grant, ACM MM 2018 & 2019</li>  
</ul>  

## Invited Talks 
<ul style="margin:-5px 0 25px;width:950px">
<li>Security and Privacy Risks of AI Large Models, ICIG2023, 2023-09-23. </li> 
<li>Adversarial Examples and Data Poisons, Saarland University (Guest Lecture), 2023-06-19. </li> 
<li>Computer Vision in Adversarial Scenarios, LIS - Ecole Centrale Marseille, 2023-03-03. <a href="./assets/img/Talk_Marseille.pdf">[Slides]</a> </li> 
<li>Computer Vision against Adversarial Perturbations, Hong Kong PolyU, 2022-12-16. <a href="./assets/img/PolyU_ZhengyuZhao.pdf">[Slides]</a> </li> 
<li>Transferable and Stealthy Adversarial Images, Alibaba Turing Lab, 2022-03-03. <a href="./assets/img/AIibaba_ZhengyuZhao.pdf">[Slides]</a> </li> 
<li>Transferability of Targeted Attacks, AI TIME, 2022-02-17. <a href="https://www.bilibili.com/video/BV1X44y1H7S4?spm_id_from=333.999.0.0">[Video (in Chinese)]</a> <a href="./assets/img/AITIME_ZhengyuZhao.pdf">[Slides]</a> </li>
</ul>

## Teaching
<ul style="margin:-5px 0 25px;width:950px">
<li>Teaching Assistant, <a href="https://cms.cispa.saarland/amlm2023/">Advanced Lecture: Attacks Against Machine Learning Models</a> (2023 Summer), Saarland University</li>
</ul>  

## Miscellaneous
<ul style="margin:-5px 0 25px;width:950px">
<li>I like simple yet effective research ideas.</li>
<li>I respect <a href="https://nicholas.carlini.com/">Dr. Nicholas Carlini</a> for his long-term dedication to evaluating adversarial robustness.</li>
<li>I love music, particularly Chinese music.</li>
  
{% include_relative _includes/contact.md %}
